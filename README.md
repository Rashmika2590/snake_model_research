# Active Contour Model (Snake) for Image Segmentation

feat/active-contour-model-project
This project implements and evaluates an Active Contour Model (ACM) for image segmentation. It provides both a standard serial implementation and a highly optimized parallel version using Numba.

The application supports both standard execution and interactive modes for manual contour initialization and real-time visualization of the snake's evolution.
This project implements and evaluates an Active Contour Model (ACM) for image segmentation. It provides both a standard serial implementation and a highly optimized parallel version using Numba to demonstrate the performance benefits of parallelization.
main

## Project Structure

- `/src`: Source code for the ACM implementations, utilities, and configuration.
- `/tests`: Test scripts for ensuring code correctness.
- `/data`: Sample images for testing and benchmarking.
- `/results`: Output images, performance logs, and plots.
- `run_benchmarks.py`: A script to automate the performance evaluation.

## Setup

1.  **Clone the repository:**
    ```bash
    git clone <repository_url>
    cd <repository_name>
    ```

2.  **Install dependencies:**
    It is recommended to use a virtual environment.
    ```bash
    python3 -m venv venv
    source venv/bin/activate
    pip install -r requirements.txt
    ```

3.  **Generate Test Data:**
    The required test images can be generated by running the script in the `tests` directory.
    ```bash
    python3 tests/generate_test_images.py
    ```

## Usage

You can run the Active Contour Model on a single image using `src/main.py`.

feat/active-contour-model-project
### Basic Execution

To run the model in batch mode and save the final result:
```bash
# Run with default automatic initialization and save the final image
python3 src/main.py --image data/circle_256.png --mode parallel
```
The output image will be saved in the `/results` directory.

### Interactive Features

The script provides flags for interactive contour initialization and real-time visualization.

**Note:** These features require a graphical display (a desktop environment) and will **not** work in a headless environment (like a standard cloud server or Docker container).

**1. Manual Initialization (`--init manual`)**

Draw the initial contour yourself instead of using the default circle. A window will open where you can click to place points.
-   **Press 'Enter'** to finalize the contour.
-   **Press 'c'** to clear all points and start over.
-   **Press 'q'** to quit.

```bash
python3 src/main.py --image data/circle_256.png --init manual
```

**2. Real-time Visualization (`--realtime`)**

Watch the snake evolve iteration by iteration. Press 'q' in the visualization window to stop the process.

```bash
python3 src/main.py --image data/circle_256.png --realtime --mode parallel
```

You can combine these flags to manually draw a contour and then watch it evolve:
```bash
python3 src/main.py --image data/circle_256.png --init manual --realtime --mode parallel
```
=======
### Serial Execution

To run the standard serial version:
```bash
python3 src/main.py --image data/circle_256.png --mode serial
```

### Parallel Execution

To run the Numba-optimized parallel version:
```bash
python3 src/main.py --image data/circle_256.png --mode parallel
```

The output images will be saved in the `/results` directory.
 main

## Performance Benchmarking

To reproduce the performance evaluation and generate the comparison plots, run the `run_benchmarks.py` script from the root directory.

```bash
python3 run_benchmarks.py
```

This script will:
1.  Run both serial and parallel implementations on all test images (`256x256`, `512x512`, `1024x1024`).
2.  Log the execution times to `results/performance_log.csv`.
feat/active-contour-model-project
3.  Generate and save comparison plots in the `results` directory.
3.  Generate and save the following plots in the `results` directory:
    -   `execution_time_vs_size.png`
    -   `speedup_vs_size.png`
main

The final performance analysis can be found in `results/performance_report.md`.
